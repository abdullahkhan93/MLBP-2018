{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Basic Principles 2018 - Data Analysis Project Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All the text in italics is instructions for filling the template - remove when writing the project report!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Title* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Title should be concise and informative, describes the approach to solve the problem. Some good titles from previous years:*\n",
    "\n",
    "*- Comparing extreme learning machines and naive bayes’ classifier in spam detection*\n",
    "\n",
    "*- Using linear discriminant analysis in spam detection*\n",
    "\n",
    "*Some not-so-good titles:*\n",
    "\n",
    "*- Bayesian spam filtering with extras*\n",
    "\n",
    "*- Two-component classifier for spam detection*\n",
    "\n",
    "*- CS-E3210 Term Project, final report*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Precise summary of the whole report, previews the contents and results. Must be a single paragraph between 100 and 200 words.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Background, problem statement, motivation, many references, description of\n",
    "contents. Introduces the reader to the topic and the broad context within which your\n",
    "research/project fits*\n",
    "\n",
    "*- What do you hope to learn from the project?*\n",
    "*- What question is being addressed?*\n",
    "*- Why is this task important? (motivation)*\n",
    "\n",
    "*Keep it short (half to 1 page).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Briefly describe data (class distribution, dimensionality) and how will it affect\n",
    "classification. Visualize the data. Don’t focus too much on the meaning of the features,\n",
    "unless you want to.*\n",
    "\n",
    "*- Include histograms showing class distribution.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of Regularization Constant (C): 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5137614678899083\n",
      "Testing Accuracy:  0.5050736497545009\n",
      "Final Score:  0.5050736497545009 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.514525993883792\n",
      "Testing Accuracy:  0.5073649754500819\n",
      "Final Score:  0.5073649754500819 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.514525993883792\n",
      "Testing Accuracy:  0.5076923076923077\n",
      "Final Score:  0.5076923076923077 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.17279999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5168195718654435\n",
      "Testing Accuracy:  0.5080196399345336\n",
      "Final Score:  0.5080196399345336 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.20735999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5168195718654435\n",
      "Testing Accuracy:  0.5090016366612111\n",
      "Final Score:  0.5090016366612111 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.24883199999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.518348623853211\n",
      "Testing Accuracy:  0.5086743044189853\n",
      "Final Score:  0.5086743044189853 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.29859839999999993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.518348623853211\n",
      "Testing Accuracy:  0.5086743044189853\n",
      "Final Score:  0.5086743044189853 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.3583180799999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5191131498470948\n",
      "Testing Accuracy:  0.5096563011456628\n",
      "Final Score:  0.5096563011456628 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.4299816959999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5191131498470948\n",
      "Testing Accuracy:  0.509328968903437\n",
      "Final Score:  0.509328968903437 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.5159780351999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5191131498470948\n",
      "Testing Accuracy:  0.5096563011456628\n",
      "Final Score:  0.5096563011456628 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.6191736422399998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5191131498470948\n",
      "Testing Accuracy:  0.5099836333878887\n",
      "Final Score:  0.5099836333878887 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.7430083706879997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5198776758409785\n",
      "Testing Accuracy:  0.5099836333878887\n",
      "Final Score:  0.5099836333878887 \n",
      "\n",
      "Inverse of Regularization Constant (C): 0.8916100448255997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5191131498470948\n",
      "Testing Accuracy:  0.5099836333878887\n",
      "Final Score:  0.5099836333878887 \n",
      "\n",
      "Inverse of Regularization Constant (C): 1.0699320537907195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5206422018348624\n",
      "Testing Accuracy:  0.5103109656301146\n",
      "Final Score:  0.5103109656301146 \n",
      "\n",
      "Inverse of Regularization Constant (C): 1.2839184645488635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5214067278287462\n",
      "Testing Accuracy:  0.5103109656301146\n",
      "Final Score:  0.5103109656301146 \n",
      "\n",
      "Inverse of Regularization Constant (C): 1.5407021574586361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5214067278287462\n",
      "Testing Accuracy:  0.5103109656301146\n",
      "Final Score:  0.5103109656301146 \n",
      "\n",
      "Inverse of Regularization Constant (C): 1.8488425889503632\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-871140f91aa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Fitting the refined training sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYTrainR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;31m# Calculation of training accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1357\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m                       sample_weight=sample_weight)\n\u001b[1;32m-> 1359\u001b[1;33m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    981\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    823\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    789\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarm_start_sag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m                 is_saga=(solver == 'saga'))\n\u001b[0m\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    329\u001b[0m                             \u001b[0mintercept_decay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                             \u001b[0mis_saga\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m                             verbose)\n\u001b[0m\u001b[0;32m    332\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Dependencies\n",
    "'''\n",
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn import metrics as met\n",
    "from sklearn.model_selection import train_test_split as TTSplit\n",
    "from sklearn.metrics import classification_report as ClassRep\n",
    "from sklearn.metrics import confusion_matrix as ConfMat\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn import preprocessing, svm, ensemble\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Data Import from Files\n",
    "'''\n",
    "# Reading the train and test files\n",
    "XTrainData = pd.read_csv(\"train_data.csv\", header = None).values\n",
    "YTrainData = pd.read_csv(\"train_labels.csv\", header = None).values\n",
    "XTestData = pd.read_csv(\"test_data.csv\", header = None).values\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Data Normalization\n",
    "'''\n",
    "#Initialization of Scalers/Transformers/Normalizers\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "normalize = preprocessing.Normalizer()\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state = 0)\n",
    "\n",
    "# Normalize the data with standard\n",
    "#XTrainData = standard_scaler.fit_transform(XTrainData)\n",
    "#TestData = standard_scaler.fit_transform(XTestData)\n",
    "\n",
    "# Normalize the data with minmax\n",
    "#XTrainData = min_max_scaler.fit_transform(XTrainData)\n",
    "#TestData = min_max_scaler.fit_transform(XTestData)\n",
    "\n",
    "# Normalize the data with robust scaler\n",
    "XTrainData = robust_scaler.fit_transform(XTrainData)\n",
    "XTestData = robust_scaler.fit_transform(XTestData)\n",
    "\n",
    "# Normalize the data with Normalize\n",
    "#XTrainData = normalize.fit_transform(XTrainData)\n",
    "#XTestData = normalize.fit_transform(XTestData)\n",
    "\n",
    "# Scale data onto Uniform Distribution [0, 1]\n",
    "#XTrainData = quantile_transformer.fit_transform(XTrainData)\n",
    "#XTestData = quantile_transformer.fit_transform(XTestData)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Data Splits (Test and Train Sets)\n",
    "'''\n",
    "# Splitting the Test Data into Training and Testing Sets (both Features and Labels) \n",
    "XTrainSet, XTestSet, YTrainSet, YTestSet = TTSplit(XTrainData, YTrainData, test_size = 0.7)\n",
    "Test_LabelSet_Size = len(YTestSet)\n",
    "Train_LabelSet_Size = len(YTrainSet)\n",
    "\n",
    "# Reshaping and preparing the training and testing sets. (R put with variable name (R = Refined)) \n",
    "# (Just re-shaped for now. To be refined later)\n",
    "YTestR = np.reshape(YTestSet, (Test_LabelSet_Size, 1))\n",
    "YTrainR = np.reshape(YTrainSet, (Train_LabelSet_Size, 1))\n",
    "\n",
    "\n",
    "\n",
    "''' \n",
    "Multinomial Logistic Regression on the data\n",
    "    Iterations = 5000\n",
    "    Inverse Regularization Constant = 0.1 till 10\n",
    "    Solver = SAGA\n",
    "    Penalty = L1\n",
    "'''\n",
    "'''\n",
    "C = 0.1\n",
    "testAcc = []\n",
    "validAcc = []\n",
    "C_array = []\n",
    "\n",
    "\n",
    "while C < 10:\n",
    "    print('Inverse of Regularization Constant (C):', C)\n",
    "    logreg = LogReg(penalty = 'l1', C = C, max_iter = 5000, solver ='saga', multi_class = 'multinomial')\n",
    "\n",
    "    # Fitting the refined training sets \n",
    "    logreg.fit(XTrainSet, YTrainR.ravel())\n",
    "\n",
    "    # Calculation of training accuracy\n",
    "    predictTest = logreg.predict(XTestSet)\n",
    "    predictTrain = logreg.predict(XTrainSet)\n",
    "\n",
    "    # Display the calculated accuracies\n",
    "    print('Training Accuracy: ', met.accuracy_score(predictTrain, YTrainR))\n",
    "    print('Testing Accuracy: ', met.accuracy_score(predictTest, YTestR))\n",
    "    testAcc.append(met.accuracy_score(predictTrain, YTrainR))\n",
    "    validAcc.append(met.accuracy_score(predictTest, YTestR))\n",
    "    C_array.append(C)\n",
    "    \n",
    "    # Display final score from Logistic Regression\n",
    "    \n",
    "    score = logreg.score(XTestSet, YTestSet)\n",
    "    print('Final Score: ', score, '\\n')\n",
    "    \n",
    "    # Increase constant until > 10\n",
    "    C = C * 1.2\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' \n",
    "Gradient Boosting Classifier on the data\n",
    "    Default Settings\n",
    "'''\n",
    "'''\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc.fit(XTrainSet, YTrainR.ravel())\n",
    "predictTest = gbc.predict(XTestSet)\n",
    "predictTrain = gbc.predict(XTrainSet)\n",
    "score = gbc.score(XTestSet, YTestSet)\n",
    "print('Training Accuracy: ', met.accuracy_score(predictTrain, YTrainR))\n",
    "print('Testing Accuracy: ', met.accuracy_score(predictTest, YTestR))\n",
    "print('Final Score: ', score, '\\n')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "''' \n",
    "Random Forest Classifier on the data\n",
    "    Default Settings\n",
    "'''\n",
    "'''\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(XTrainSet, YTrainR.ravel())\n",
    "predictTest = rfc.predict(XTestSet)\n",
    "predictTrain = rfc.predict(XTrainSet)\n",
    "score = rfc.score(XTestSet, YTestSet)\n",
    "print('Training Accuracy: ', met.accuracy_score(predictTrain, YTrainR))\n",
    "print('Testing Accuracy: ', met.accuracy_score(predictTest, YTestR))\n",
    "print('Final Score: ', score, '\\n')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' \n",
    "RBF SVM Classifier on the data\n",
    "    Default Settings\n",
    "'''\n",
    "\n",
    "rbfsvm = svm.SVC()\n",
    "rbfsvm.fit(XTrainSet, YTrainR.ravel())\n",
    "predictTest = rbfsvm.predict(XTestSet)\n",
    "predictTrain = rbfsvm.predict(XTrainSet)\n",
    "score = rbfsvm.score(XTestSet, YTestSet)\n",
    "print('Training Accuracy: ', met.accuracy_score(predictTrain, YTrainR))\n",
    "print('Testing Accuracy: ', met.accuracy_score(predictTest, YTestR))\n",
    "print('Final Score: ', score, '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(C_array,testAcc)\n",
    "plt.plot(C_array,validAcc)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogReg(C = 1.85, max_iter = 7500, solver ='sag', multi_class = 'multinomial', n_jobs = -2)\n",
    "logreg.fit(XTrainSet, YTrainSet.ravel())\n",
    "predictTrain = logreg.predict(XTrainSet)\n",
    "print('Training Accuracy: ', met.accuracy_score(predictTrain, YTrainSet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('logreg.xlsx', engine = 'xlsxwriter')\n",
    "pd.DataFrame(logreg.predict(XTestData)).to_excel(writer, sheet_name = 'accuracy')\n",
    "pd.DataFrame(logreg.predict_proba(XTestData)).to_excel(writer, sheet_name = 'logloss')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41898527004909986 with 1 neighbors\n",
      "Accuracy: 0.492962356792144 with 2 neighbors\n",
      "Accuracy: 0.5014729950900164 with 3 neighbors\n",
      "Accuracy: 0.5155482815057283 with 4 neighbors\n",
      "Accuracy: 0.5132569558101473 with 5 neighbors\n",
      "Accuracy: 0.5227495908346972 with 6 neighbors\n",
      "Accuracy: 0.5253682487725041 with 7 neighbors\n",
      "Accuracy: 0.534860883797054 with 8 neighbors\n",
      "Accuracy: 0.5404255319148936 with 9 neighbors\n",
      "Accuracy: 0.5472995090016367 with 10 neighbors\n",
      "Accuracy: 0.5515548281505729 with 11 neighbors\n",
      "Accuracy: 0.5518821603927987 with 12 neighbors\n",
      "Accuracy: 0.5515548281505729 with 13 neighbors\n",
      "Accuracy: 0.5574468085106383 with 14 neighbors\n",
      "Accuracy: 0.5561374795417349 with 15 neighbors\n",
      "Accuracy: 0.5571194762684124 with 16 neighbors\n",
      "Accuracy: 0.5610474631751228 with 17 neighbors\n",
      "Accuracy: 0.5607201309328969 with 18 neighbors\n",
      "Accuracy: 0.5613747954173486 with 19 neighbors\n",
      "Accuracy: 0.5623567921440262 with 20 neighbors\n",
      "Accuracy: 0.5643207855973813 with 21 neighbors\n",
      "Accuracy: 0.5646481178396072 with 22 neighbors\n",
      "Accuracy: 0.563011456628478 with 23 neighbors\n",
      "Accuracy: 0.5643207855973813 with 24 neighbors\n",
      "Accuracy: 0.564975450081833 with 25 neighbors\n",
      "Accuracy: 0.5636661211129296 with 26 neighbors\n",
      "Accuracy: 0.5636661211129296 with 27 neighbors\n",
      "Accuracy: 0.5636661211129296 with 28 neighbors\n",
      "Accuracy: 0.5666121112929624 with 29 neighbors\n",
      "Accuracy: 0.5695581014729951 with 30 neighbors\n",
      "Accuracy: 0.5702127659574469 with 31 neighbors\n",
      "Accuracy: 0.5695581014729951 with 32 neighbors\n",
      "Accuracy: 0.5685761047463175 with 33 neighbors\n",
      "Accuracy: 0.5666121112929624 with 34 neighbors\n",
      "Accuracy: 0.564975450081833 with 35 neighbors\n",
      "Accuracy: 0.5643207855973813 with 36 neighbors\n",
      "Accuracy: 0.5613747954173486 with 37 neighbors\n",
      "Accuracy: 0.5613747954173486 with 38 neighbors\n",
      "Accuracy: 0.5610474631751228 with 39 neighbors\n",
      "Accuracy: 0.5639934533551555 with 40 neighbors\n",
      "Accuracy: 0.562684124386252 with 41 neighbors\n",
      "Accuracy: 0.563011456628478 with 42 neighbors\n",
      "Accuracy: 0.5600654664484451 with 43 neighbors\n",
      "Accuracy: 0.562684124386252 with 44 neighbors\n",
      "Accuracy: 0.5620294599018003 with 45 neighbors\n",
      "Accuracy: 0.5636661211129296 with 46 neighbors\n",
      "Accuracy: 0.5633387888707038 with 47 neighbors\n",
      "Accuracy: 0.5639934533551555 with 48 neighbors\n",
      "Accuracy: 0.562684124386252 with 49 neighbors\n",
      "Accuracy: 0.5617021276595745 with 50 neighbors\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "k_array = []\n",
    "acc = []\n",
    "for k in range(50):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k+1, n_jobs = -2)\n",
    "    neigh.fit(XTrainSet, YTrainSet.ravel())\n",
    "    predLabels = neigh.predict(XTestSet)\n",
    "    conf = confusion_matrix(YTestSet, predLabels)\n",
    "    accuracy = np.trace(conf)/np.sum(conf)\n",
    "    k_array.append(k+1)\n",
    "    acc.append(accuracy)\n",
    "    print('Accuracy:', accuracy,'with', k+1, 'neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22895651cc0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(k_array,acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5623567921440262\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=20, n_jobs = -2)\n",
    "neigh.fit(XTrainSet, YTrainSet)\n",
    "predLabels = neigh.predict(XTestSet)\n",
    "conf = confusion_matrix(YTestSet, predLabels)\n",
    "accuracy = np.trace(conf)/np.sum(conf)\n",
    "print('Accuracy:', accuracy)\n",
    "logloss = neigh.predict_proba(XTestSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('kneigh.xlsx', engine = 'xlsxwriter')\n",
    "pd.DataFrame(neigh.predict(XTestData)).to_excel(writer, sheet_name = 'accuracy')\n",
    "pd.DataFrame(neigh.predict_proba(XTestData)).to_excel(writer, sheet_name = 'logloss')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNTESTED\n",
    "def logLoss(probabilities):\n",
    "    probabilities = probabilities / np.sum(probabilities, axis = 1) #normalize sums of probabilities to 1\n",
    "    classes = np.argmax(probabilities, axis = 1)\n",
    "    logsum = 0\n",
    "    for i in range(probabilities.shape[0]):\n",
    "        logsum += np.log(probabilities[i,classes[i]])\n",
    "    return logsum/probabilities.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of the input data\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods and experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*- Explain your whole approach (you can include a block diagram showing the steps in your process).* \n",
    "\n",
    "*- What methods/algorithms, why were the methods chosen. *\n",
    "\n",
    "*- What evaluation methodology (cross CV, etc.).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials with ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Summarize the results of the experiments without discussing their implications.*\n",
    "\n",
    "*- Include both performance measures (accuracy and LogLoss).*\n",
    "\n",
    "*- How does it perform on kaggle compared to the train data.*\n",
    "\n",
    "*- Include a confusion matrix.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion/Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpret and explain your results *\n",
    "\n",
    "*- Discuss the relevance of the performance measures (accuracy and LogLoss) for\n",
    "imbalanced multiclass datasets. *\n",
    "\n",
    "*- How the results relate to the literature. *\n",
    "\n",
    "*- Suggestions for future research/improvement. *\n",
    "\n",
    "*- Did the study answer your questions? *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*List of all the references cited in the document*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "*Any additional material needed to complete the report can be included here. For example, if you want to keep  additional source code, additional images or plots, mathematical derivations, etc. The content should be relevant to the report and should help explain or visualize something mentioned earlier. **You can remove the whole Appendix section if there is no need for it.** *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
